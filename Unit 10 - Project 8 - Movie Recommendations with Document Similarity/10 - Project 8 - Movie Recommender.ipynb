{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 8 - Movie Recommendations with Document Similarity\n",
    "\n",
    "Recommender systems are one of the popular and most adopted applications of machine learning. They are typically used to recommend entities to users and these entites can be anything like products, movies, services and so on. \n",
    "\n",
    "Popular examples of recommendations include,\n",
    "- Amazon suggesting products on its website\n",
    "- Amazon Prime, Netflix, Hotstar recommending movies\\shows\n",
    "- YouTube recommending videos to watch\n",
    "\n",
    "Typically recommender systems can be implemented in three ways:\n",
    "\n",
    "- Simple Rule-based Recommenders: Typically based on specific global metrics and thresholds like movie popularity, global ratings etc.\n",
    "- Content-based Recommenders: This is based on providing similar entities based on a specific entity of interest. Content metadata can be used here like movie descriptions, genre, cast, director and so on\n",
    "- Collaborative filtering Recommenders: Here we don't need metadata but we try to predict recommendations and ratings based on past ratings of different users and specific items.\n",
    "\n",
    "We will be building a movie recommendation system here where based on data\\metadata pertaining to different movies, we try and recommend similar movies of interest!\n",
    "\n",
    "![](netflix_rec.png)\n",
    "\n",
    "Since our focus in not really recommendation engines but NLP, we will be leveraging the text-based metadata for each movie to try and recommend similar movies based on specific movies of interest. This falls under content-based recommenders. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('tmdb_5000_movies.csv.gz', compression='gzip')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[['title', 'tagline', 'overview', 'genres', 'popularity']]\n",
    "df.tagline.fillna('', inplace=True)\n",
    "df['description'] = df['tagline'].map(str) + ' ' + df['overview']\n",
    "df.dropna(inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Turn: Build a Movie Recommender System\n",
    "\n",
    "Here you will build your own movie recommender system. We will use the following pipeline:\n",
    "- Text pre-processing\n",
    "- Feature Engineering\n",
    "- Document Similarity Computation\n",
    "- Find top similar movies\n",
    "- Build a movie recommendation function\n",
    "\n",
    "\n",
    "## Document Similarity\n",
    "\n",
    "Recommendations are about understanding the underlying features which make us favour one choice over the other. Similarity between items(in this case movies) is one way to understanding why we choose one movie over another. There are different ways to calculate similarity between two items. One of the most widely used measures is __cosine similarity__ which we have already used in the previous unit.\n",
    "\n",
    "### Cosine Similarity\n",
    "\n",
    "Cosine Similarity is used to calculate a numeric score to denote the similarity between two text documents. Mathematically, it is defined as follows:\n",
    "\n",
    "$$ cosine(x,y) = \\frac{x. y^\\intercal}{||x||.||y||} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text pre-processing\n",
    "\n",
    "We will do some basic text pre-processing on our movie descriptions before we build our features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    # tokenize document\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "normalize_corpus = np.vectorize(normalize_document)\n",
    "\n",
    "norm_corpus = normalize_corpus(list(df['description']))\n",
    "len(norm_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf = TfidfVectorizer(ngram_range=(1, 2), min_df=2)\n",
    "tfidf_matrix = tf.fit_transform(df['description'])\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Pairwise Document Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "doc_sim = cosine_similarity(tfidf_matrix)\n",
    "doc_sim_df = pd.DataFrame(doc_sim)\n",
    "doc_sim_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get List of Movie Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies_list = df['title'].values\n",
    "movies_list, movies_list.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort Dataset by Popular Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pop_movies = df.sort_values(by='popularity', ascending=False)\n",
    "pop_movies.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Top Similar Movies for a Sample Movie\n",
    "\n",
    "Let's take __Minions__ the most popular movie the the dataframe above and try and find the most similar movies which can be recommended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find movie ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_idx = np.where(movies_list == 'Minions')[0][0]\n",
    "movie_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get movie similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_similarities = doc_sim_df.iloc[movie_idx].values\n",
    "movie_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get top 5 similar movie IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "similar_movie_idxs = np.argsort(-movie_similarities)[1:6]\n",
    "similar_movie_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get top 5 similar movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "similar_movies = movies_list[similar_movie_idxs]\n",
    "similar_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn: Build a movie recommender function to recommend top 5 similar movies for any movie \n",
    "\n",
    "The movie title, movie title list and document similarity matrix dataframe will be given as inputs to the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def movie_recommender(movie_title, movies=movies_list, doc_sims=doc_sim_df):\n",
    "    # find movie id\n",
    "    _____\n",
    "    # get movie similarities\n",
    "    _____\n",
    "    # get top 5 similar movie IDs\n",
    "    _____\n",
    "    # get top 5 movies\n",
    "    similar_movies = _____\n",
    "    # return the top 5 movies\n",
    "    return similar_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn: Now use this function on the top 20 popular movies\n",
    "\n",
    "Hint: Try getting the first 20 titles from the `popular_movies` dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "popular_movies = _____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for movie in popular_movies:\n",
    "    print('Movie:', movie)\n",
    "    print('Top 5 recommended Movies:', movie_recommender(movie_title=movie))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Similar Movies\n",
    "\n",
    "Now that we built our own movie recommendation utility, it is time to level up.\n",
    "\n",
    "Clustering is an unsupervised approach to find groups of similar items in any given dataset. There are different clustering algorithms and __K-Means__ is a pretty simple yet affect one. Most movies span different emotions and can be categorized into multiple genres (same is the case with movies listed in our current dataset). Can clustering of movie descriptions help us understand these groupings?\n",
    "\n",
    "Similarity analysis was a good starting point, but can we do better? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, max_iter=100,random_state=42).fit(____) #feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Counter(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying K\n",
    "\n",
    "Since most movies are a combination of emotions, stories, characters, scenary, etc, let us try and utilize K-means to see if the movies can be grouped into common themes capturing some of these underlying aspects.\n",
    "\n",
    "One challenge we face while working with K-Means is finding the right value of K. To do so, there are a few heuristics like _the silhouette_score_ and the _elbow_ method. \n",
    "\n",
    "### Sillhouette Score\n",
    "Silhouette Scoring helps in quantifying interpretation and validation of consistency within clusters of data. \n",
    "The silhouette score value quantifies how similar an item is to its own cluster (cohesion) compared to other clusters (separation). The silhouette score ranges from −1 to +1, where a high value indicates well placed item. A negative score indicates that there may be too many or too few clusters.\n",
    "\n",
    "### Elbow Method\n",
    "This method requires us to run k-means clustering on a given dataset for a range of values of k. Then for each value of k, we calculate sum of squared errors (SSE).\n",
    "\n",
    "The next step is to plot a line graph of the SSE aganist each value of k. The line graph looks like an arm, the _elbow_ on the arm is the value of optimal k (number of cluster). \n",
    "The goal is to choose a small value of k that still has a low SSE, and the elbow usually represents where we start to have diminishing returns by increasing k.\n",
    "\n",
    "The following snippet loops through different values of K, generates the silhouette scores as well the elbow plot to help us narrow down to the optimal value of K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identify_k(feature_matrix, min_k=2,max_k=3):\n",
    "    sse = {}\n",
    "    for k in range(min_k,max_k):\n",
    "        kmeans = KMeans(n_clusters=k, max_iter=100,random_state=42).fit(_____)#feature matrix\n",
    "        sil_coeff = silhouette_score(tfidf_matrix, \n",
    "                                     _________,# cluster labels \n",
    "                                     metric='euclidean')\n",
    "        print(\"For K={}, Silhouette Coefficient = {}\".format(k, sil_coeff))\n",
    "        # Inertia: Sum of distances of samples to their closest cluster center\n",
    "        sse[k] = kmeans.inertia_ \n",
    "    plt.figure()\n",
    "    plt.plot(_______, ______) # x-axis=different values of k, y-axis=sse value for each k\n",
    "    plt.xlabel(\"K\")\n",
    "    plt.ylabel(\"SSE\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn\n",
    "Find the optimal value of K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# iterate from k=2 to k=10 and plot the elbow curve\n",
    "identify_k(___,___,____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Cluster Labels\n",
    "For the current scenario, let us set __K=4__ and assign cluster labels to each of the movies in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(________).fit(____)\n",
    "df[\"cluster_label\"] = ______ # cluster labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Cluster Details\n",
    "\n",
    "Each cluster constitutes movies which have some underlying aspects which are common.\n",
    "We also understand that cluster centers are in a way representatives of the whole cluster. Let us utilize this understanding to extract top common features amongst clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cluster_details(clustering_obj, movie_data, \n",
    "                     feature_names, num_clusters,\n",
    "                     topn_features=10):\n",
    "\n",
    "    cluster_details = {}  \n",
    "    # get cluster centroids\n",
    "    ordered_centroids = clustering_obj.cluster_centers_.argsort()[:, ::-1]\n",
    "    \n",
    "    # get key features for each cluster\n",
    "    # get movies belonging to each cluster\n",
    "    for cluster_num in range(num_clusters):\n",
    "        cluster_details[cluster_num] = {}\n",
    "        cluster_details[cluster_num]['cluster_num'] = ____ # set cluster number\n",
    "        key_features = [_________]# extract key features from centroids\n",
    "        cluster_details[cluster_num]['key_features'] = key_features\n",
    "        \n",
    "        movies = ____________ # assign list of movies belonging to this cluster\n",
    "        cluster_details[cluster_num]['movies'] = movies\n",
    "    \n",
    "    return cluster_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_cluster_details(cluster_data,n_movies=5):\n",
    "    # print cluster details\n",
    "    for cluster_num, cluster_details in cluster_data.items():\n",
    "        print('Cluster {} details:'.format(cluster_num))\n",
    "        print('-'*20)\n",
    "        print('Key features:', ______)\n",
    "        print('Movies in this cluster:')\n",
    "        print(', '.join(_________))\n",
    "        print('='*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn\n",
    "\n",
    "Extract Cluster Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_data =  get_cluster_details(clustering_obj=____, # clustering object\n",
    "                                     movie_data=df,\n",
    "                                     feature_names=_____, #hint:use the tfidf vectorizer to get list of features\n",
    "                                     num_clusters=4,\n",
    "                                     topn_features=5)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_cluster_details(______) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heirarchical Clustering\n",
    "add content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import ward, dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ward_hierarchical_clustering(feature_matrix):\n",
    "    \n",
    "    cosine_distance = ________ # 1- cosine similarity of the features\n",
    "    linkage_matrix = ward(cosine_distance)\n",
    "    return linkage_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_hierarchical_clusters(linkage_matrix, movie_data, p=100, figure_size=(8,12)):\n",
    "    # set size\n",
    "    fig, ax = plt.subplots(figsize=figure_size) \n",
    "    movie_titles = _______ # extract movie titles as list\n",
    "    \n",
    "    # prepare dendrogram\n",
    "    R = dendrogram(linkage_matrix, \n",
    "                   orientation=\"left\", \n",
    "                   labels=movie_titles,\n",
    "                   truncate_mode='lastp',\n",
    "                   p=p, \n",
    "                   no_plot=True)\n",
    "    \n",
    "    temp = {R[\"leaves\"][ii]: movie_titles[ii] for ii in range(len(R[\"leaves\"]))}\n",
    "    def llf(xx):\n",
    "        return \"{}\".format(temp[xx])\n",
    "    \n",
    "    # plot dendrogram\n",
    "    ax = dendrogram(\n",
    "            ______, # linkage matrix\n",
    "            truncate_mode='lastp',\n",
    "            orientation=\"left\",\n",
    "            p=p,  \n",
    "            leaf_label_func=_____, # function to get leaf labels \n",
    "            leaf_font_size=10.,\n",
    "            )\n",
    "    plt.tick_params(axis= 'x',   \n",
    "                    which='both',  \n",
    "                    bottom='off',\n",
    "                    top='off',\n",
    "                    labelbottom='off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('movie_hierachical_clusters.png', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn\n",
    "\n",
    "Use the above prepare utilities to perform hierarchical clustering and generate a dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linkage_matrix = ward_hierarchical_clustering(______)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_hierarchical_clusters(___________)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
